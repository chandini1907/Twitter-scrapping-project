import snscrape.modules.twitter as sntwitter
import pandas as pd
import streamlit as st
import datetime
import pymongo
from pymongo import MongoClient
import time

#df_tweets=pd.DataFrame()-----------?
#title of web page
st.title("Twitter Scrapper")
genre=st.radio("Enter Your",('Keyword','Hashtag'))
word=st.text_input("What you want to search?")
start=st.date_input("Enter your start date(YYYY/MM/DD)",datetime.date(2022,1,1))
end=st.date_input("Enter your end date(YYYY/MM/DD)",datetime.date(2023,1,1))
limit= st.slider('Select a Limit:', 0, 1000, 10)

# Creating list to append tweet data to
tweets_list2 = []


# Using TwitterSearchScraper to scrape data and append tweets to list

if genre=='Keyword':
    for i,tweet in enumerate(sntwitter.TwitterSearchScraper(f'{word} + since:{start} until:{end}').get_items()):
        if i>limit:
            break
        tweets_list2.append([ tweet.id, tweet.date,  tweet.content, tweet.lang, tweet.user.username, tweet.replyCount, tweet.retweetCount,tweet.likeCount, tweet.source, tweet.url ])
    df_tweets = pd.DataFrame(tweets_list2, columns=['ID','Date','Content', 'Language', 'Username', 'ReplyCount', 'RetweetCount', 'LikeCount','Source', 'Url'])
else:
    for i,tweet in enumerate(sntwitter.TwitterHashtagScraper(f'{word} + since:{start} until:{end}').get_items()):
        if i>limit:
            break            
        tweets_list2.append([ tweet.id, tweet.date,  tweet.content, tweet.lang, tweet.user.username, tweet.replyCount, tweet.retweetCount,tweet.likeCount, tweet.source, tweet.url ])
    df_tweets = pd.DataFrame(tweets_list2, columns=['ID','Date','Content', 'Language', 'Username', 'ReplyCount', 'RetweetCount', 'LikeCount','Source', 'Url'])

#download into mongodb

if st.button("Download into mongodb"):
    client=pymongo.MongoClient("mongodb://localhost:27017")
    df_tweets.to_csv('collection.csv',mode='a')
    df=pd.read_csv('collection.csv',encoding='unicode_escape')
    datamongo=df.to_dict(orient="records")
    db=client["twitter_collection"]
    db.collection.insert_many(datamongo)
    st.success('Successfully uploaded to MongoDB', icon="âœ…")


#Download csv file
@st.cache
def convert_df(df):
    return df.to_csv().encode('utf-8')
if not df_tweets.empty:
    csv=convert_df(df_tweets)
    st.download_button(label="Download csv file",data=csv,file_name='Twitter_df.csv',mime='text/csv',)

#download json file
    json_string = df_tweets.to_json(orient ='records')
    st.download_button(label="Download Json File",file_name="Twitter_df.json",mime="application/json",data=json_string,)


# Creating a dataframe from the tweets list above
if st.button("Your Dataframe"):
    st.dataframe(df_tweets)
