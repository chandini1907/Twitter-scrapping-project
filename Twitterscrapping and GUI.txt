#import modules
import snscrape.modules.twitter as sntwitter
import streamlit as st
import pandas as pd
import pymongo
import datetime

#create a textinput for the hashtag
hashtag=input("Enter the username or Hashtag:")

#connect to the database
client=pymongo.MongoClient('mongodb://127.0.0.1:2017')
db=client.scraped_data

#scrape tweets
tweetlist=[]
limit=1000
for tweet in sntwitter.TwitterSearchScraper('{}'.format(hashtag)).get_items():
    if len(tweetlist)==limit:
        break
    else:
        tweetlist.append({'date':tweet.date,'ID':tweet.id,'url':tweet.url,'Tweet content':tweet.content,'user':tweet.user.username,'language':tweet.lang,'hashtag':tweet.hashtags,'replycount':tweet.replyCount,'retweetcount':tweet.retweetCount,'likecount':tweet.likeCount})

#store the data in a collection
start_date=datetime.datetime(2023,1,1)
end_date=datetime.datetime(2023,1,20)
time_interval=end_date-start_date
collection=db[hashtag+str(time_interval)]

#upload data to database
if st.button('upload to database'):
    client=pymongo.MongoClient('mongodb://127.0.0.1:27017')
    db=client.scraped_data
    collection=db[hashtag+str(time_interval)]
    st.success('Data uploaded to the database')

#convert the collection to a dataframe
data=pd.DataFrame(list(collection.find()))

#dataframe
print(data)

#Download the dataframe in csv format
data.to_csv(f"{hashtag}_tweetlist.csv",index=False)

#Download the dataframe in json format
data.to_json(f"{hashtag}_tweetlist.json",orient="records",force_ascii=False,indent=4,default_handler=str)
